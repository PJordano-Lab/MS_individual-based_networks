---
title: "Null model network comparisons"
author: "Elena Quintero"
date: "`r Sys.Date()`"
output: github_document
---


```{r include = F}
knitr::opts_chunk$set(message = FALSE)
knitr::opts_chunk$set(warning = FALSE)
```


```{r, message=F}
library(here)
library(tidyverse)
library(magrittr)
library(bipartite)
library(igraph)
library(tnet)
```

## Read networks

1. Read individual-based networks:

```{r message=FALSE, results='hide'}
ind.files <- list.files(here("networks/nets_raw"))

nets.ind <- str_sub(ind.files, 1, 5)

#remove small nets
nets.selec.ind <- nets.ind[! nets.ind %in% c("08_01", "12_01", "12_06", "12_07")]

nets.ind <- list()

for (i in 1:length(nets.selec.ind)) {
  
  print(nets.selec.ind[i])
    
    net <- read_csv(here::here(paste0("networks/nets_raw/",
                                        nets.selec.ind[i],
                                        "_int.csv")))

    nets.ind[[i]] <- net
    names(nets.ind)[i] <- nets.selec.ind[i]

}
```


2. Read species-based networks:

```{r message=FALSE, results='hide'}
sp.files <- list.files(here("networks/nets_sp_raw"))

nets.sp <- str_sub(sp.files, 1, 8)

#remove small nets
nets.selec.sp <- nets.sp[! nets.sp %in% c("sp_03_01", "sp_03_02",
                                          "sp_03_03", "sp_03_04",
                                          "sp_05_01", "sp_09_01",
                                          "sp_29_12", "sp_31_01",
                                          "sp_44_01")]

nets.sp <- list()

for (i in 1:length(nets.selec.sp)) {
    
    print(nets.selec.sp[i])
    
    net <- read.csv(here::here(paste0("networks/nets_sp_raw/",
                                        nets.selec.sp[i],
                                        ".csv")), sep = ";")

   nets.sp[[i]] <- net
   names(nets.sp)[i] <- nets.selec.sp[i]
  
}
```

3rd. combine all nets, convert to matrix format and ceiling to have integer values:

```{r}
nets <- c(nets.ind, nets.sp)

convert_to_matrix <- function(net){
  if(colnames(net)[1] == "ind"){
    net <- net |> column_to_rownames("ind")
  }
  else{
    net <- net |> column_to_rownames("sp")
  }
  
  net <- ceiling(net)
}

nets <- lapply(nets, convert_to_matrix)
```



## NULL MODELS

Generate 1000 random nets following *Patefield*'s algorithm (keeps constant marginal rows and columns)

```{r}
null.list <- vector("list", 105)

for (i in 1:length(nets)) {
  
  print(i)
  
  nulls <- nullmodel(nets[[i]], N = 1000, method = "r2dtable") 

  null.list[[i]] <- nulls
  
  names(null.list)[[i]] <- names(nets)[i]
  
}
```

Generate 1000 random nets following *Vazquez* algorithm (keeps constant marginal rows and columns)

```{r}
#vaznull.list <- list()
vaznull.list <- vector("list", 105)

for (i in 1:length(nets)) {
  
  print(i)
  
  nulls <- nullmodel(nets[[i]], N = 1000, method = "vaznull")
  
  #vaznull.list <- append(vaznull.list, list(nulls))
  vaznull.list[[i]] <- nulls
  
  names(vaznull.list)[[i]] <- names(nets)[i]
  
}
```

Control ind-based nets by sampling effort when needed: 

```{r}
## Read sampling effort parameters:
params <- read_csv2(here("networks/nets_se/nets_parameters.csv")) |> 
  mutate(type = str_sub(net_code, 1,3))

# List of individual-based networks
net_id <- params$net_id
# List of sampling effort for each individual-based networks
se_net <- params$sampling_effort
# List of whether individuals require controlling by sampling effort
control_needed <- params$necessary_stand

# Read info on sampling effort for individual-based network:
nets.ind.se <- list()

for (i in 1:length(nets.selec.ind)) {
  
  if (control_needed[i] == "YES") {
    
    print(net_id[i])
    
    effort <- read_csv(here::here(paste0("networks/nets_se/",
                                         nets.selec.ind[i],
                                         "_attr.csv"))) |>
      select(ind, SE = se_net[i]) |> 
      mutate(ind = as.character(ind))

    nets.ind.se[[i]] <- effort
    names(nets.ind.se)[i] <- nets.selec.ind[i]
  
  }
  else {
  }
}
```

```{r}
## Divide null model networks that need control by sampling effort:

control_se <- function(net_list, i) {
  
  # Check if control is needed and type is 'ind'
  if (control_needed[i] == "YES" & params$type[i] == "ind") {
    print(i)
    
    # Apply to each of the 1000 networks (j)
    net_list <- lapply(net_list, function(net) {
      
      net <- net/nets.ind.se[[i]][[2]]
      
      return(net)
    })
  }
  
  return(net_list)
}

# Apply the control_se function to null models list using lapply
null.list.se <- lapply(seq_along(null.list), function(i) control_se(null.list[[i]], i))
names(null.list.se) <- names(null.list)

vaznull.list.se <- lapply(seq_along(vaznull.list), function(i) control_se(vaznull.list[[i]], i))
names(vaznull.list.se) <- names(vaznull.list)
```

Standardize all matrices for subsequent analysis:

```{r, message=FALSE, results='hide'}
# Function to apply gts transformation to a single network
gts <- function(net) {
  mat_gts <- net / sum(net)
  return(mat_gts)
}

# Function to apply gts to a list of networks (nested lists)
gts_list <- function(net_list) {
  # Use lapply to apply 'gts' to each element in the sublist
  return(lapply(net_list, gts))
}

# Apply the gts_list function to the main list (nested lists)
null.list.std <- lapply(null.list.se, gts_list)
names(null.list.std) <- names(null.list)

vaznull.list.std <- lapply(vaznull.list.se, gts_list)
names(vaznull.list.std) <- names(vaznull.list)
```


## Calculate network level metrics:

```{r}
indices <- as.list(c("number of species",
                     "connectance", 
                     "weighted NODF",
                     "interaction evenness", 
                     "Alatalo interaction evenness"))
```

```{r}
# Progress bar initialization
pb <- txtProgressBar(min = 0, max = length(nets), style = 3)

# Initialize web.metrics list
web.metrics <- lapply(1:length(vaznull.list), function(x) vector("list", 1000))

# Function to compute bipartite metrics
compute_bipartite_metrics <- function(net) {
  m.bipart <- networklevel(net, indices)
  return(as.data.frame(t(m.bipart)))
}

# Function to compute modularity
compute_modularity <- function(net) {
  mod <- computeModules(net)
  return(mod@likelihood)
}

# Function to compute igraph metrics
compute_igraph_metrics <- function(net) {
  inet <- graph_from_biadjacency_matrix(net, weighted = TRUE, add.names = NULL)
  assortativity <- assortativity_degree(inet)
  eigen.centrality <- eigen_centrality(inet)$value
  centr_binary <- centr_eigen(inet, scale = TRUE, normalized = TRUE)$centralization
  centr_weighted_obs <- sum(max(eigen_centrality(inet)$vector) - eigen_centrality(inet)$vector)
  centralization_w <- centr_weighted_obs / centr_eigen(inet)$theoretical_max
  return(cbind(assortativity, eigen.centrality, centr_binary, centralization_w))
}

# Umbrella function to process each network and iteration
process_network <- function(i, null_list) {
  
  net_nulls <- null_list[[i]]
  
  metrics_list <- lapply(1:1000, function(j) {
    
    m.bipart <- compute_bipartite_metrics(net_nulls[[j]])
    
    M <- compute_modularity(net_nulls[[j]])
    
    igraph.metrics <- compute_igraph_metrics(net_nulls[[j]])
    
    # Merge all metrics
    metrics.nulls <- cbind(m.bipart, M, igraph.metrics) %>%
      select_all(~gsub("\\s+", ".", .)) %>%
      mutate(net_size = number.of.species.HL * number.of.species.LL,
             iter = j)
    
    # Add type and net_id
    if (str_detect(names(null_list)[i], "sp")) {
      metrics.nulls <- metrics.nulls %>%
        mutate(type = "sp", net_id = str_sub(names(null_list)[i], 4, 8))
    } else {
      metrics.nulls <- metrics.nulls %>%
        mutate(type = "ind", net_id = str_sub(names(null_list)[i], 1, 5))
    }
    
    return(metrics.nulls)
  })
  
  return(metrics_list)
}
```

Run umbrella function for each *Vazquez* null model network:

```{r}
# Main lapply for each network
web.metrics <- lapply(1:length(vaznull.list.std), function(i) {
  metrics <- process_network(i, vaznull.list.std)
  
  # Update progress bar
  setTxtProgressBar(pb, i)
  
  return(metrics)
})
```

Makes one data.table from a list of many

```{r}
web.metrics.df <- data.table::rbindlist(
  lapply(1:length(web.metrics), function(i) {
  data.table::rbindlist(web.metrics[[i]])
  })
  )

web.metrics.df <- web.metrics.df |> 
  relocate(type, .before = everything()) |> 
  relocate(net_id, .after = type) |> 
  relocate(iter, .after = net_id) |> 
  mutate(net_code = paste0(type, "_", net_id)) |> 
  group_by(iter) |> 
  mutate(net_n = order(net_code))

glimpse(web.metrics.df)

saveRDS(web.metrics.df, here("data/net_level_nulls_vaz.rds"))
```


Run umbrella function for each *Patefield* null model network:

```{r}
web.metrics.pat <- lapply(1:length(null.list.std), function(i) {
  metrics <- process_network(i, null.list.std)

  # Update progress bar
  setTxtProgressBar(pb, i)

  return(metrics)
})

web.metrics.pat.df <- data.table::rbindlist(
  lapply(1:length(web.metrics.pat), function(i) {
  data.table::rbindlist(web.metrics.pat[[i]])
  })
  )

web.metrics.pat.df <- web.metrics.pat.df |>
  relocate(type, .before = everything()) |>
  relocate(net_id, .after = type) |>
  relocate(iter, .after = net_id) |>
  mutate(net_code = paste0(type, "_", net_id)) |>
  group_by(iter) |>
  mutate(net_n = order(net_code))

glimpse(web.metrics.pat.df)

saveRDS(web.metrics.pat.df, here("data/net_level_nulls_pat.rds"))
```

```{r}

```


